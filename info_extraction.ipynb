{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d08d9de-4d58-4547-b2dc-5ef1e1bf92c8",
   "metadata": {},
   "source": [
    "<div style=\"position: relative; text-align: center;\">\n",
    "  <img src=\"imagenes/portada.png\" alt=\"INE\" width=\"50%\">\n",
    "</div> <br><br>\n",
    "\n",
    "\n",
    "<p style=\"text-align: center; font-size: 20px;\"><u>ÍNDICE</u></p>\n",
    "\n",
    "<span style=\"font-size: 20px;\">\n",
    "\n",
    "1. **Introducción**\n",
    "\n",
    "2. **Importación de paquetes**<br>\n",
    "\n",
    "3. **Funciones**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.1. Función de limpieza<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.2. Funcion de inicialización<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.3. Función de extracción de información<br>\n",
    "\n",
    "5.  **Proceso de extracción de información**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.1. Inicializo variables<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.2. Extracción de información<br>\n",
    "\n",
    "6. **Comprobación de resultados**<br>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0fc9ef-8b08-4f4e-8b0b-16dcbc98761f",
   "metadata": {},
   "source": [
    "# 1. Introducción\n",
    "\n",
    "<span style=\"font-size: 20px;\">\n",
    "\n",
    "El presente proyecto tratará de extraer información relevante de faturas de luz. Para ello se presentan diferentes modelos de facturas en formato PDF que, mediante el método empleado de extracción de información, esta se guardará en archivos con formato JSON.\n",
    "\n",
    "El método empleado para la extracción de información ha sido la utilización de un LLM junto con la librería Kor. Esta librería nos permite crear un esquema(*véase Apéndice 1.*) para especificar que información debe ser extraida, generando un prompt que mandará a nuestro LLM.\n",
    "Los archivos PDF se han leido con la librería Pypdf y el texto se ha limpiado bajo criterio personal, pudiendo mejorarse.\n",
    "\n",
    "Este método puede implementarse utilizando LLM's open source como LLaMa 3, haciendo un finetuning(*véase Apéndice 2.*) con los datos de entrenamiento y aplicando el mismo procedimiento. No se ha realizado en este caso por carecer de procesamiento suficiente, por lo que se ha optado por el modelo 'gpt-3.5-turbo' de OPENAI.\n",
    "\n",
    "Se han comparado los resultados obtenidos entre el modelo 'gpt-3.5-turbo' y el modelo LLaMa 3-70b(a traves de GROQ), obteniendo prácticamente identicos resultados.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c190afa5-100c-4522-b14d-830cd42d5285",
   "metadata": {},
   "source": [
    "# 2. Importación de paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b009712d-618a-47c4-b8c7-241219507f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from pypdf import PdfReader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from typing import List, Optional\n",
    "from kor.extraction import create_extraction_chain\n",
    "from kor.nodes import Object, Text\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4292aabb-6940-4212-9511-d273c1a11f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9bcd6b-88b2-41b5-8382-abd0bdc531cc",
   "metadata": {},
   "source": [
    "# 3. Funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7fd700-107e-48cc-a63c-e12da9b2ebe6",
   "metadata": {},
   "source": [
    "## 3.1. Función de limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "463eff8d-7759-4d85-bd6f-904a25332357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bill_cleaner(path):\n",
    "\n",
    "    \"\"\"\n",
    "    Función que devuelve el texto procesado de una factura.\n",
    "\n",
    "    Input:\n",
    "        - path(str): Ruta de la factura.pdf\n",
    "    \n",
    "    Output:\n",
    "        - texto_limpio (str)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    factura = PdfReader(path)\n",
    "    \n",
    "    texto_factura = \"\"\n",
    "    for pagina in factura.pages:\n",
    "        texto_factura += pagina.extract_text()\n",
    "    \n",
    "    # Elimino hiperlinks:\n",
    "    texto_limpio = re.sub(r'\\b(?:http://|https://|www\\.)?\\S+(?:-|\\s)?\\S*?(?:\\.com|\\.es)\\b', \"\", texto_factura).strip()\n",
    "    \n",
    "    # Elimino conjuntos de puntos mayores a 1:\n",
    "    texto_limpio = re.sub(r'\\.{2,}', \"\", texto_limpio).strip()\n",
    "    \n",
    "    # Elimino espacios multiples en blanco y saltos de linea:\n",
    "    texto_limpio = re.sub(r\"\\s+\", \" \", texto_limpio)\n",
    "\n",
    "    return texto_limpio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b950551-3bbf-45f0-aa6b-8e48f48a68f7",
   "metadata": {},
   "source": [
    "## 3.2. Funcion de inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "477d7f8f-b2f0-478c-8376-97b77d075c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializar():\n",
    "\n",
    "    data_path = input(\"Introduce la ruta donde se encuentran las facturas de las que deseas extraer información: \")\n",
    "\n",
    "    model = input(\"Selecciona OPENAI(1) o LLaMa(2): \")\n",
    "\n",
    "    if model == \"1\":\n",
    "        nombre = input(\"Introduce el nombre asociado a la API key de OPENAI que aparece en tu archivo .ENV: \")\n",
    "        api_key = os.getenv(nombre)\n",
    "    if model == \"2\":\n",
    "        nombre = input(\"Introduce el nombre asociado a la API key de GROQ que aparece en tu archivo .ENV: \")\n",
    "        api_key = os.getenv(nombre)\n",
    "\n",
    "    return data_path, model, api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12b5f9c-ab1d-4ab4-9d5e-891733daa5f0",
   "metadata": {},
   "source": [
    "## 3.3. Función de extracción de información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fd7ec5f7-d10f-4eb0-a0c2-cef0a305fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_extractor(path, model, api_key):\n",
    "\n",
    "    \"\"\"\n",
    "    Función que extrae la información requerida de una factura de luz guardandola en formato JSON.\n",
    "\n",
    "    Input:\n",
    "        - path(str): Ruta donde se alojan las factura en formato PDF\n",
    "        - api_key(str): La api key de OPENAI o GROQ\n",
    "    \n",
    "    Output:\n",
    "        - archivo JSON con la información requerida de la factura.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Defino el LLM:\n",
    "    if model == \"1\":\n",
    "        llm = ChatOpenAI(\n",
    "            model_name=\"gpt-3.5-turbo\",\n",
    "            temperature=0,\n",
    "            openai_api_key= api_key)\n",
    "        \n",
    "    if model == \"2\":\n",
    "        llm = ChatGroq(model=\"llama3-70b-8192\",\n",
    "                       groq_api_key= api_key)   \n",
    "\n",
    "\n",
    "    # Cargo el esquema:\n",
    "    with open(\"utils/schema.pkl\", \"rb\") as f:\n",
    "        schema = pickle.load(f)\n",
    "\n",
    "    # Cargo cadena\n",
    "    chain = create_extraction_chain(llm, schema, encoder_or_encoder_class=\"json\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Busco las facturas en PDF en la ruta proporcionada:\n",
    "    \n",
    "    facturas = glob.glob(os.path.join(path, \"*.pdf\"))\n",
    "\n",
    "    # Obtengo la información requerida de cada factura:\n",
    "    \n",
    "    if not os.path.exists(\"extracted_information\"):\n",
    "        os.makedirs(\"extracted_information\")\n",
    "    \n",
    "    barra_progreso = tqdm(total= len(facturas), desc=\"Progreso\", unit=\"archivo\")\n",
    "    \n",
    "    for path_factura in facturas:\n",
    "        file_name = path_factura.split(\"\\\\\")[1].split(\".\")[0] + \".json\"\n",
    "        extracted_information_path = \"extracted_information\\\\\"\n",
    "\n",
    "        ###################################### Limpieza texto ######################################\n",
    "        \n",
    "        texto_factura = bill_cleaner(path_factura)\n",
    "\n",
    "        ###################################### Extracción de información requerida ######################################\n",
    "        \n",
    "        informacion_factura = chain.invoke(input= texto_factura)[\"text\"][\"data\"][\"informacion_factura\"][0]\n",
    "\n",
    "        ###################################### Guardo en formato JSON la informacion ######################################\n",
    "        with open(extracted_information_path + file_name, \"w\") as json_file:\n",
    "            json.dump(informacion_factura, json_file, indent=4)\n",
    "\n",
    "        \n",
    "        barra_progreso.update(1)\n",
    "\n",
    "    barra_progreso.close()\n",
    "\n",
    "    return extracted_information_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1676d25c-f4bc-498a-9a2d-eaf288a08d05",
   "metadata": {},
   "source": [
    "## 3.4. Función para el cálculo de la distancia de Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0d80d6b8-b742-4bce-95d7-1bd2f9a3aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(str1, str2):\n",
    "    '''\n",
    "    Función para el cálculo de la distancia de Levenshtein.\n",
    "    \n",
    "    Input:\n",
    "        - str1(str): String de la predicción.\n",
    "        - str2(str): String del test.\n",
    "    \n",
    "    Output:\n",
    "        - Distancia de Levenshtein.\n",
    "    '''\n",
    "    \n",
    "    d=dict()\n",
    "    for i in range(len(str1)+1):\n",
    "      d[i]=dict()\n",
    "      d[i][0]=i\n",
    "    for i in range(len(str2)+1):\n",
    "      d[0][i] = i\n",
    "    for i in range(1, len(str1)+1):\n",
    "      for j in range(1, len(str2)+1):\n",
    "         d[i][j] = min(d[i][j-1]+1, d[i-1][j]+1, d[i-1][j-1]+(not str1[i-1] == str2[j-1]))\n",
    "    return d[len(str1)][len(str2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc769220-df1a-4905-8652-607da07a0d35",
   "metadata": {},
   "source": [
    "## 3.5. Función para el cálculo del score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cdbcab00-7896-46f9-b8d0-b340c4336de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(json_test, json_predicho):\n",
    "    '''\n",
    "    Función para calcular el score entre dos archivos JSON, uno es de test y el otro el predicho.\n",
    "\n",
    "    Input:\n",
    "        - json_test(JSON): Archivo JSON de la factura test.\n",
    "        - json_predicho(JSON): Archivo JSON de la factura predicha.\n",
    "    \n",
    "    Output:\n",
    "        - Score entre la información test y la predicha.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    distancias = []\n",
    "    for key in list(json_test.keys()):\n",
    "        str_1 = str(json_predicho[key])\n",
    "        str_2 = str(json_test[key])\n",
    "\n",
    "        if len(str_2) == 0:\n",
    "            distancia = 0\n",
    "\n",
    "        else:\n",
    "            distancia = 1 - (distance(str_1, str_2)/len(str_2))\n",
    "            \n",
    "        distancias.append(distancia)    \n",
    "    \n",
    "    score = (1/len(json_test.keys()))*sum(distancias)\n",
    "    \n",
    "    return score    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b12cc8-d7e2-4fc9-9675-fda9e95bfe24",
   "metadata": {},
   "source": [
    "## 3.6. Función para el cálculo del score total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2fa60196-4f27-4c86-a07d-560e7b03b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_total(path_test, path_pred):\n",
    "    '''\n",
    "    Función que devuelve la media de los scores obtenidos para cada documento\n",
    "\n",
    "    Input:\n",
    "        - path_test(str): Ruta donde se alojan los archivos JSON test.\n",
    "        - path_pred(str): Ruta donde se alojan los archivos JSON predichos.\n",
    "    \n",
    "    Output:\n",
    "        - Media Score.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    json_predichos = glob.glob(os.path.join(path_pred, \"*.json\"))\n",
    "\n",
    "    archivos_pred = []\n",
    "    for i in json_predichos:\n",
    "        archivo = i.split(\"\\\\\")[1]\n",
    "        archivos_pred.append(archivo)\n",
    "\n",
    "    json_tests = [path_test + archivo for archivo in archivos_pred]\n",
    "\n",
    "    scores = []\n",
    "    for test, pred in zip(json_tests, json_predichos):\n",
    "        \n",
    "        with open(test, \"r\", encoding= \"utf-8\") as archivo_test:\n",
    "            factura_test = json.load(archivo_test)\n",
    "            \n",
    "        with open(pred, \"r\", encoding= \"utf-8\") as archivo_pred:\n",
    "            factura_pred = json.load(archivo_pred)\n",
    "    \n",
    "        scr = score(factura_test, factura_pred)\n",
    "        scores.append(scr)\n",
    "    \n",
    "    media = round(sum(scores)/len(scores), 3)\n",
    "    \n",
    "    return media    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0002fa2b-bf0e-408a-b446-e03f65ee96c6",
   "metadata": {},
   "source": [
    "# 4. Proceso de extracción de información"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b329ea-8988-4164-b2f3-071185b2454d",
   "metadata": {},
   "source": [
    "## 4.1. Inicializo variables\n",
    "\n",
    "<span style=\"font-size:larger;\">\n",
    "\n",
    "* **data_path**: Es la carperta donde se encuentran las facturas en pdf\n",
    "* **openai_api_key**: La clave de la API de OPENAI en el archivo .env\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "- <u>*Usando gpt-3.5-turbo*</u>:\n",
    "\n",
    "```\r",
    "api_key= os.getenv(\"OPENAI_API_KEY\")\n",
    "data_path = \"data/\"\n",
    "```\n",
    "\n",
    "- <u>*Usando LLaMa 3-70b*</u>:\n",
    "\n",
    "```\n",
    "api_key= os.getenv(\"GROQ_API_KEY\")\n",
    "data_path = \"data/\"\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "<u>**Ejecuta la siguiente linea de código para inicializar las variables y comenzar con el proceso de extracción de información**</u>:\n",
    "\n",
    "   \n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a557f36a-9b9c-4f67-be0d-a5a17835dea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Introduce la ruta donde se encuentran las facturas de las que deseas extraer información:  data/\n",
      "Selecciona OPENAI(1) o LLaMa(2):  1\n",
      "Introduce el nombre asociado a la API key de OPENAI que aparece en tu archivo .ENV:  OPENAI_API_KEY\n"
     ]
    }
   ],
   "source": [
    "data_path, model, api_key = inicializar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2e42da-e3b4-4811-be0b-0b62f8b57d7c",
   "metadata": {},
   "source": [
    "## 4.2. Extracción de información\n",
    "\n",
    "<span style=\"font-size:larger;\">\n",
    "\n",
    "La <u>**siguiente linea de código**</u> ejecutará la función para <u>**extraer información**</u> de las facturas, creando la carpeta *extracted_information* donde se guardará la información de cada una de las faturas en formato JSON, llevando el mismo nombre de la factura correspondiente.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1d2e7758-0369-4e42-a484-9eb243301058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\regue\\conda_ENV\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "Progreso: 100%|██████████| 3/3 [00:16<00:00,  5.42s/archivo]\n"
     ]
    }
   ],
   "source": [
    "extracted_information_path = information_extractor(data_path, model, api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88b6472-550f-485f-820b-e7bb24e5b103",
   "metadata": {},
   "source": [
    "# 5. Comprobación de resultados\n",
    "<span style=\"font-size:larger;\">\n",
    "Los resultados se han comprobado mediante una media de una métrica basada en la distancia de Levenshtein de todos los campos de todos los documentos, y se expresará en porcentaje.\n",
    "\n",
    "Se requieren los siguientes campos para comprobar el score obtenido:\n",
    "\n",
    "* **data_path**: Es la carperta donde se encuentran los archivos JSON de las facturas test\n",
    "* **extracted_information_path**: Es la carperta donde se encuentran los archivos JSON de las facturas predichas\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ca521b6-9017-4c72-aa26-832b90cf4ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_total(data_path, extracted_information_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
